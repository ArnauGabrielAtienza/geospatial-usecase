{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloudbutton Geospatial: Water Consumption Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:27.706148Z",
     "start_time": "2021-04-13T14:38:27.027515Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from cloudbutton_geospatial.io_utils.plot import plot_results\n",
    "from cloudbutton_geospatial.utils.notebook import date_picker\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from shapely.geometry import Point, MultiPoint, box\n",
    "from pprint import pprint\n",
    "import functools\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lithops\n",
    "import requests\n",
    "import rasterio\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import tempfile\n",
    "import concurrent.futures\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from lithops.storage import Storage\n",
    "from lithops.storage.utils import StorageNoSuchKeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area outside the processed tile that we want to consider for taking SIAM stations into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:28.795793Z",
     "start_time": "2021-04-13T14:38:28.788173Z"
    }
   },
   "outputs": [],
   "source": [
    "AREA_OF_INFLUENCE = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lithops Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:29.658886Z",
     "start_time": "2021-04-13T14:38:29.654251Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_BUCKET = 'geospatial-usecase'\n",
    "COMPUTE_BACKEND = 'localhost'\n",
    "STORAGE_BACKEND = 'localhost'\n",
    "RUNTIME = None\n",
    "RUNTIME_MEMORY = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM_ASC_PREFIX = 'DTMs/asc/'\n",
    "DTM_GEOTIFF_PREFIX = 'DTMs/geotiff/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split tile into square chunks (number of tiles = SPLITS^2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:30.525082Z",
     "start_time": "2021-04-13T14:38:30.519883Z"
    }
   },
   "outputs": [],
   "source": [
    "SPLITS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation coefficient between elevation and temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:31.362634Z",
     "start_time": "2021-04-13T14:38:31.359578Z"
    }
   },
   "outputs": [],
   "source": [
    "r = -0.0056"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elevation to interpolate temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:32.187402Z",
     "start_time": "2021-04-13T14:38:32.184798Z"
    }
   },
   "outputs": [],
   "source": [
    "zdet = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day of year to calculate solar irradiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790d329b5aae4245bbee67669fe3c7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date = date_picker(default=datetime.date(2022, 5, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:33.304420Z",
     "start_time": "2021-04-13T14:38:33.299098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAY_OF_YEAR = date.value.timetuple().tm_yday\n",
    "DAY_OF_YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:28:46,278 [INFO] lithops.storage.backends.localhost.localhost -- Localhost storage client created\n"
     ]
    }
   ],
   "source": [
    "storage = lithops.storage.Storage(backend=STORAGE_BACKEND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:28:46,507 [INFO] lithops.config -- Lithops v2.6.0\n",
      "2022-06-02 08:28:46,510 [INFO] lithops.storage.backends.localhost.localhost -- Localhost storage client created\n",
      "2022-06-02 08:28:46,512 [INFO] lithops.localhost.localhost -- Localhost compute client created\n"
     ]
    }
   ],
   "source": [
    "fexec = lithops.FunctionExecutor(backend=COMPUTE_BACKEND, storage=STORAGE_BACKEND, runtime=RUNTIME, runtime_memory=RUNTIME_MEMORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get meteorological data for selected date (12:00h) and station locations from Catalonia Open Data portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "XEMA_DATA_URL = 'https://analisi.transparenciacatalunya.cat/resource/nzvn-apee.json'\n",
    "XEMA_META_STATIONS = 'https://analisi.transparenciacatalunya.cat/resource/yqwd-vj5e.json'\n",
    "XEMA_META_VARS = 'https://analisi.transparenciacatalunya.cat/resource/4fb2-n3yi.json'\n",
    "\n",
    "@functools.cache\n",
    "def get_meteo_stations():\n",
    "    if os.path.exists('meta_cache/meteo_stations.csv'):\n",
    "        print('Getting meteo station from local cache')\n",
    "        with open('meta_cache/meteo_stations.csv', 'r') as f:\n",
    "            stations_meta = pd.read_csv(f)\n",
    "        return stations_meta\n",
    "    \n",
    "    print('Fetching meteo station from analisi.transparenciacatalunya.cat...')\n",
    "    res = requests.get(XEMA_META_STATIONS, params={'NOM_ESTAT': f'Operativa'})\n",
    "    stations_meta = pd.DataFrame(res.json())\n",
    "    return stations_meta\n",
    "\n",
    "@functools.cache\n",
    "def get_meteo_variables():\n",
    "    if os.path.exists('meta_cache/meteo_variables.csv'):\n",
    "        print('Getting meteo variables from local cache')\n",
    "        with open('meta_cache/meteo_variables.csv', 'r') as f:\n",
    "            vars_meta = pd.read_csv(f)\n",
    "        return vars_meta\n",
    "            \n",
    "    print('Fetching meteo station from analisi.transparenciacatalunya.cat...')\n",
    "    res = requests.get(XEMA_META_VARS)\n",
    "    vars_meta = pd.DataFrame(res.json())\n",
    "    return vars_meta\n",
    "    \n",
    "def get_meteo_data(date, stations_meta, vars_meta):\n",
    "    if os.path.exists(f'meta_cache/meteo-meta-{date.isoformat()}.csv'):\n",
    "        print('Getting meteo variables from local cache')\n",
    "        with open(f'meta_cache/meteo-meta-{date.isoformat()}.csv', 'r') as f:\n",
    "            vars_meta = pd.read_csv(f)\n",
    "        return vars_meta\n",
    "    res = requests.get(XEMA_DATA_URL, params={'data_lectura': f'{date.isoformat()}T12:00:00.000'})\n",
    "    xema_day = pd.DataFrame(res.json()).set_index('id')\n",
    "    \n",
    "    merged = xema_day.merge(stations_meta, on=\"codi_estacio\").merge(vars_meta, on=\"codi_variable\")\n",
    "    merged = merged[[\"codi_estacio\", \"nom_estacio\", \"latitud\", \"longitud\", \"acronim\", \"valor_lectura\"]]\n",
    "    \n",
    "    merged_transposed = (merged.groupby(['codi_estacio', 'nom_estacio', 'latitud', 'longitud'])\n",
    "                         .apply(lambda group: group[['acronim', 'valor_lectura']].set_index('acronim').T.reset_index(drop=True).rename_axis(None, axis=1))\n",
    "                         .reset_index().drop(['level_4'], axis=1).set_index('codi_estacio'))\n",
    "    return merged_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting meteo station from local cache\n",
      "Getting meteo variables from local cache\n",
      "Getting meteo variables from local cache\n"
     ]
    }
   ],
   "source": [
    "meteo_stations = get_meteo_stations()\n",
    "meteo_vars = get_meteo_variables()\n",
    "meteo_data = get_meteo_data(date.value, meteo_stations, meteo_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronim</th>\n",
       "      <th>nom_variable</th>\n",
       "      <th>unitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PPTx1min</td>\n",
       "      <td>Precipitació màxima en 1 minut</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HRx</td>\n",
       "      <td>Humitat relativa màxima</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VV10</td>\n",
       "      <td>Velocitat del vent a 10 m (esc.)</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DV10</td>\n",
       "      <td>Direcció de vent 10 m (m. 1)</td>\n",
       "      <td>°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>Temperatura</td>\n",
       "      <td>°C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HR</td>\n",
       "      <td>Humitat relativa</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P</td>\n",
       "      <td>Pressió atmosfèrica</td>\n",
       "      <td>hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PPT</td>\n",
       "      <td>Precipitació</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RS</td>\n",
       "      <td>Irradiància solar global</td>\n",
       "      <td>W/m²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GNEU</td>\n",
       "      <td>Gruix de neu a terra</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tx</td>\n",
       "      <td>Temperatura màxima</td>\n",
       "      <td>°C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tn</td>\n",
       "      <td>Temperatura mínima</td>\n",
       "      <td>°C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HRn</td>\n",
       "      <td>Humitat relativa mínima</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VV2</td>\n",
       "      <td>Velocitat del vent a 2 m (esc.)</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DV2</td>\n",
       "      <td>Direcció del vent a 2 m (m. 1)</td>\n",
       "      <td>°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>VV6</td>\n",
       "      <td>Velocitat del vent a 6 m (esc.)</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DV6</td>\n",
       "      <td>Direcció del vent a 6 m (m. 1)</td>\n",
       "      <td>°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VVx10</td>\n",
       "      <td>Ratxa màxima del vent a 10 m</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DVVx10</td>\n",
       "      <td>Direcció de la ratxa màxima del vent a 10 m</td>\n",
       "      <td>°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VVx6</td>\n",
       "      <td>Ratxa màxima del vent a 6 m</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DVVx6</td>\n",
       "      <td>Direcció de la ratxa màxima del vent a 6 m</td>\n",
       "      <td>°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VVx2</td>\n",
       "      <td>Ratxa màxima del vent a 2 m</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DVVx2</td>\n",
       "      <td>Direcció de la ratxa màxima del vent a 2 m</td>\n",
       "      <td>°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RN</td>\n",
       "      <td>Irradiància neta</td>\n",
       "      <td>W/m²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Px</td>\n",
       "      <td>Pressió atmosfèrica màxima</td>\n",
       "      <td>hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pn</td>\n",
       "      <td>Pressió atmosfèrica mínima</td>\n",
       "      <td>hPa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acronim                                 nom_variable unitat\n",
       "0   PPTx1min               Precipitació màxima en 1 minut     mm\n",
       "1        HRx                      Humitat relativa màxima      %\n",
       "2       VV10             Velocitat del vent a 10 m (esc.)    m/s\n",
       "3       DV10                 Direcció de vent 10 m (m. 1)      °\n",
       "4          T                                  Temperatura     °C\n",
       "5         HR                             Humitat relativa      %\n",
       "6          P                          Pressió atmosfèrica    hPa\n",
       "7        PPT                                 Precipitació     mm\n",
       "8         RS                     Irradiància solar global   W/m²\n",
       "9       GNEU                         Gruix de neu a terra     mm\n",
       "10        Tx                           Temperatura màxima     °C\n",
       "11        Tn                           Temperatura mínima     °C\n",
       "12       HRn                      Humitat relativa mínima      %\n",
       "13       VV2              Velocitat del vent a 2 m (esc.)    m/s\n",
       "14       DV2               Direcció del vent a 2 m (m. 1)      °\n",
       "15       VV6              Velocitat del vent a 6 m (esc.)    m/s\n",
       "16       DV6               Direcció del vent a 6 m (m. 1)      °\n",
       "17     VVx10                 Ratxa màxima del vent a 10 m    m/s\n",
       "18    DVVx10  Direcció de la ratxa màxima del vent a 10 m      °\n",
       "19      VVx6                  Ratxa màxima del vent a 6 m    m/s\n",
       "20     DVVx6   Direcció de la ratxa màxima del vent a 6 m      °\n",
       "21      VVx2                  Ratxa màxima del vent a 2 m    m/s\n",
       "22     DVVx2   Direcció de la ratxa màxima del vent a 2 m      °\n",
       "23        RN                             Irradiància neta   W/m²\n",
       "24        Px                   Pressió atmosfèrica màxima    hPa\n",
       "25        Pn                   Pressió atmosfèrica mínima    hPa"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteo_vars[['acronim', 'nom_variable', 'unitat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codi_estacio</th>\n",
       "      <th>nom_estacio</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>Tx</th>\n",
       "      <th>Px</th>\n",
       "      <th>Pn</th>\n",
       "      <th>HRx</th>\n",
       "      <th>VV10</th>\n",
       "      <th>DV10</th>\n",
       "      <th>...</th>\n",
       "      <th>GNEU</th>\n",
       "      <th>VV2</th>\n",
       "      <th>DV2</th>\n",
       "      <th>VVx2</th>\n",
       "      <th>DVVx2</th>\n",
       "      <th>RN</th>\n",
       "      <th>VV6</th>\n",
       "      <th>DV6</th>\n",
       "      <th>VVx6</th>\n",
       "      <th>DVVx6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>UH</td>\n",
       "      <td>el Montmell</td>\n",
       "      <td>41.34171</td>\n",
       "      <td>1.48769</td>\n",
       "      <td>28.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1</td>\n",
       "      <td>172.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>KX</td>\n",
       "      <td>la Roca del Vallès - ETAP Cardedeu</td>\n",
       "      <td>41.61865</td>\n",
       "      <td>2.36114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>UI</td>\n",
       "      <td>Gisclareny</td>\n",
       "      <td>42.26477</td>\n",
       "      <td>1.76218</td>\n",
       "      <td>22.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>WQ</td>\n",
       "      <td>Montsec d'Ares (1.572 m)</td>\n",
       "      <td>42.05130</td>\n",
       "      <td>0.72952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>U2</td>\n",
       "      <td>Sant Pere Pescador</td>\n",
       "      <td>42.17716</td>\n",
       "      <td>3.09680</td>\n",
       "      <td>28.3</td>\n",
       "      <td>1014.5</td>\n",
       "      <td>1013.9</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DJ</td>\n",
       "      <td>Banyoles</td>\n",
       "      <td>42.11653</td>\n",
       "      <td>2.78969</td>\n",
       "      <td>27.8</td>\n",
       "      <td>994.5</td>\n",
       "      <td>994.4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>UU</td>\n",
       "      <td>Amposta</td>\n",
       "      <td>40.70776</td>\n",
       "      <td>0.63210</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1016.9</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>545.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>UP</td>\n",
       "      <td>Cabrils</td>\n",
       "      <td>41.51773</td>\n",
       "      <td>2.37702</td>\n",
       "      <td>23.9</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>174.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>572.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>D4</td>\n",
       "      <td>Roses</td>\n",
       "      <td>42.27065</td>\n",
       "      <td>3.18165</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1012.9</td>\n",
       "      <td>1012.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>UJ</td>\n",
       "      <td>Santa Coloma de Queralt</td>\n",
       "      <td>41.52879</td>\n",
       "      <td>1.36830</td>\n",
       "      <td>24.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>180.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   codi_estacio                         nom_estacio   latitud  longitud    Tx  \\\n",
       "58           UH                         el Montmell  41.34171   1.48769  28.6   \n",
       "41           KX  la Roca del Vallès - ETAP Cardedeu  41.61865   2.36114   NaN   \n",
       "59           UI                          Gisclareny  42.26477   1.76218  22.9   \n",
       "74           WQ            Montsec d'Ares (1.572 m)  42.05130   0.72952   NaN   \n",
       "47           U2                  Sant Pere Pescador  42.17716   3.09680  28.3   \n",
       "30           DJ                            Banyoles  42.11653   2.78969  27.8   \n",
       "68           UU                             Amposta  40.70776   0.63210  24.2   \n",
       "65           UP                             Cabrils  41.51773   2.37702  23.9   \n",
       "20           D4                               Roses  42.27065   3.18165  25.0   \n",
       "60           UJ             Santa Coloma de Queralt  41.52879   1.36830  24.9   \n",
       "\n",
       "        Px      Pn   HRx  VV10   DV10  ...  GNEU  VV2  DV2  VVx2  DVVx2  \\\n",
       "58     NaN     NaN  30.0   NaN    NaN  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "41     NaN     NaN   NaN   NaN    NaN  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "59     NaN     NaN  41.0   NaN    NaN  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "74     NaN     NaN   NaN   5.9    NaN  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "47  1014.5  1013.9  46.0   5.3  146.0  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "30   994.5   994.4  42.0   5.1  186.0  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "68  1016.9  1016.7  64.0   4.8  149.0  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "65  1008.0  1007.8  62.0   2.4  174.0  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "20  1012.9  1012.3  58.0   5.5  114.0  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "60     NaN     NaN  33.0   NaN    NaN  ...   NaN  NaN  NaN   NaN    NaN   \n",
       "\n",
       "       RN  VV6    DV6  VVx6  DVVx6  \n",
       "58    NaN  3.1  172.0   7.8  149.0  \n",
       "41    NaN  NaN    NaN   NaN    NaN  \n",
       "59    NaN  NaN    NaN   NaN    NaN  \n",
       "74    NaN  NaN    NaN   NaN    NaN  \n",
       "47    NaN  NaN    NaN   NaN    NaN  \n",
       "30    NaN  NaN    NaN   NaN    NaN  \n",
       "68  545.0  NaN    NaN   NaN    NaN  \n",
       "65  572.0  NaN    NaN   NaN    NaN  \n",
       "20    NaN  NaN    NaN   NaN    NaN  \n",
       "60    NaN  4.8  180.0   8.2  178.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteo_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store metadata to local cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('meta_cache/meteo_stations.csv'):\n",
    "    with open('meta_cache/meteo_stations.csv', 'w') as f:\n",
    "        meteo_stations.to_csv(f)\n",
    "\n",
    "if not os.path.exists('meta_cache/meteo_variables.csv'):\n",
    "    with open('meta_cache/meteo_variables.csv', 'w') as f:\n",
    "        meteo_vars.to_csv(f)\n",
    "        \n",
    "if not os.path.exists(f'meta_cache/meteo-meta-{date.value.isoformat()}.csv'):\n",
    "    with open(f'meta_cache/meteo-meta-{date.value.isoformat()}.csv', 'w') as f:\n",
    "        meteo_data.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload metadata to Cloud Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading meteo data to Object Storage...\n"
     ]
    }
   ],
   "source": [
    "meteo_key = f'meteo-meta-{date.value.isoformat()}.csv'\n",
    "try:\n",
    "    storage.head_object(bucket=DATA_BUCKET, key=meteo_key)\n",
    "except StorageNoSuchKeyError:\n",
    "    print('Uploading meteo data to Object Storage...')\n",
    "    body = meteo_data.to_csv().encode('utf-8')\n",
    "    storage.put_object(bucket=DATA_BUCKET, key=meteo_key, body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital Terrain Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download DTM files for free from http://centrodedescargas.cnig.es/CentroDescargas/buscadorCatalogo.do?codFamilia=MDT05# and put them in `inpit_DTMs` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_asc_keys = storage.list_keys(bucket=DATA_BUCKET, prefix=DTM_ASC_PREFIX)\n",
    "dtm_asc_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload tiles from local input folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T09:48:12.000399Z",
     "start_time": "2021-04-07T09:48:11.986192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading DTMs/asc/PNOA_MDT05_ETRS89_HU31_0359_LID.asc...\n"
     ]
    }
   ],
   "source": [
    "local_dtm_input = 'input_DTMs'\n",
    "local_dtms = [os.path.join(local_dtm_input, dtm) for dtm in os.listdir(local_dtm_input) if dtm.endswith('.asc')]\n",
    "\n",
    "def upload_file(file_path):\n",
    "    key = os.path.join(DTM_ASC_PREFIX, os.path.basename(file_path))\n",
    "    if key in dtm_asc_keys:\n",
    "        print(f'Tile {key} already in storage')\n",
    "        return key\n",
    "    with open(file_path, 'rb') as f:\n",
    "        print(f'Uploading {key}...')\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=key, body=f)\n",
    "    return key\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=16) as pool:\n",
    "    result = list(pool.map(upload_file, local_dtms))\n",
    "    # list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asc_to_geotiff(obj, storage):\n",
    "    asc_file_name = os.path.basename(obj.key)\n",
    "    tile_id, _ = os.path.splitext(asc_file_name)\n",
    "    out_path = os.path.join(tempfile.gettempdir(), tile_id + '.tiff')\n",
    "    out_key = os.path.join(DTM_GEOTIFF_PREFIX, tile_id + '.tiff')\n",
    "       \n",
    "    with rasterio.open(obj.data_stream) as src:\n",
    "        profile = src.profile\n",
    "        # Cloud optimized GeoTiff parameters\n",
    "        profile.update(driver='GTiff')\n",
    "        profile.update(blockxsize=256)\n",
    "        profile.update(blockysize=256)\n",
    "        profile.update(tiled=True)\n",
    "        profile.update(compress='deflate')\n",
    "        profile.update(interleave='band')\n",
    "        with rasterio.open(out_path, 'w', **profile) as dest:\n",
    "            dest.write(src.read())\n",
    "    \n",
    "    with open(out_path, 'rb') as f:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=out_key, body=f)\n",
    "    \n",
    "    return out_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:25:30,843 [INFO] lithops.config -- Lithops v2.6.0\n",
      "2022-06-02 08:25:30,845 [INFO] lithops.storage.backends.localhost.localhost -- Localhost storage client created\n",
      "2022-06-02 08:25:30,848 [INFO] lithops.localhost.localhost -- Localhost compute client created\n",
      "2022-06-02 08:25:30,850 [INFO] lithops.invokers -- ExecutorID c3b6f0-0 | JobID M000 - Selected Runtime: python \n",
      "2022-06-02 08:25:30,861 [INFO] lithops.invokers -- ExecutorID c3b6f0-0 | JobID M000 - Starting function invocation: asc_to_geotiff() - Total: 1 activations\n",
      "2022-06-02 08:25:30,981 [INFO] lithops.invokers -- ExecutorID c3b6f0-0 | JobID M000 - View execution logs at /tmp/lithops/logs/c3b6f0-0-M000.log\n"
     ]
    }
   ],
   "source": [
    "fs = fexec.map(asc_to_geotiff, os.path.join('localhost://', DATA_BUCKET, DTM_ASC_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:25:32,835 [INFO] lithops.wait -- ExecutorID c3b6f0-0 - Getting results from 1 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50dbdda3152c4873b2421786ea2d35e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:25:41,908 [INFO] lithops.executors -- ExecutorID c3b6f0-0 - Cleaning temporary data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DTMs/geotiff/PNOA_MDT05_ETRS89_HU31_0359_LID.tiff']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fexec.get_result(fs=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DTMs/geotiff/PNOA_MDT05_ETRS89_HU31_0359_LID.tiff']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_geotiff_keys = storage.list_keys(bucket=DATA_BUCKET, prefix=DTM_GEOTIFF_PREFIX)\n",
    "dtm_geotiff_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T09:48:13.697506Z",
     "start_time": "2021-04-07T09:48:13.691877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PNOA_MDT05_ETRS89_HU31_0359_LID']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_ids = [os.path.splitext(os.path.basename(dtm))[0] for dtm in dtm_geotiff_keys]\n",
    "tile_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert digital elevation map into a Cloud Optimized Geotiff. Upload then to IBM COS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serverless computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute solar irradiation given a day of year using GRASS libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:54.462039Z",
     "start_time": "2021-04-13T14:38:54.449706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_solar_irradiation(inputFile, outputFile, crs='32630'):\n",
    "    # Define grass working set\n",
    "    GRASS_GISDB = 'grassdata'\n",
    "    GRASS_LOCATION = 'GEOPROCESSING'\n",
    "    GRASS_MAPSET = 'PERMANENT'\n",
    "    GRASS_ELEVATIONS_FILENAME = 'ELEVATIONS'\n",
    "\n",
    "    os.environ['GRASSBIN'] = 'grass76'\n",
    "    from grass_session import Session\n",
    "    import grass.script as gscript\n",
    "    from grass.pygrass.modules.shortcuts import general\n",
    "    from grass.pygrass.modules.shortcuts import raster\n",
    "\n",
    "    os.environ.update(dict(GRASS_COMPRESS_NULLS='1'))\n",
    "    \n",
    "    # Clean previously processed data\n",
    "    if os.path.isdir(GRASS_GISDB):\n",
    "        shutil.rmtree(GRASS_GISDB)\n",
    "    \n",
    "    with Session(gisdb=GRASS_GISDB, location=GRASS_LOCATION, mapset=GRASS_MAPSET, create_opts='EPSG:32630') as ses:\n",
    "        # Set project projection to match elevation raster projection\n",
    "        general.proj(epsg=crs, flags='c') \n",
    "    \n",
    "        # Load raster file into working directory\n",
    "        raster.import_(input=inputFile, output=GRASS_ELEVATIONS_FILENAME, flags='o')    \n",
    "        \n",
    "        # Set project region to match raster region\n",
    "        general.region(raster=GRASS_ELEVATIONS_FILENAME, flags='s')    \n",
    "        # Calculate solar irradiation\n",
    "        gscript.run_command('r.slope.aspect', elevation=GRASS_ELEVATIONS_FILENAME,\n",
    "                            slope='slope', aspect='aspect')\n",
    "        gscript.run_command('r.sun', elevation=GRASS_ELEVATIONS_FILENAME,\n",
    "                            slope='slope', aspect='aspect', beam_rad='beam',\n",
    "                            step=1, day=DAY_OF_YEAR)\n",
    "        \n",
    "        # Get extraterrestrial irradiation from history metadata\n",
    "        regex = re.compile(r'\\d+\\.\\d+')\n",
    "        output = gscript.read_command(\"r.info\", flags=\"h\", map=[\"beam\"])\n",
    "        splits = str(output).split('\\n')\n",
    "        line = next(filter(lambda line: 'Extraterrestrial' in line, splits))\n",
    "        extraterrestrial_irradiance = float(regex.search(line)[0])\n",
    "        \n",
    "        # Export generated results into a GeoTiff file\n",
    "        if os.path.isfile(outputFile):\n",
    "            os.remove(outputFile)\n",
    "            \n",
    "        r.out_gdal(input='beam', output=outputFile)\n",
    "        \n",
    "        return extraterrestrial_irradiance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get stations contained in the area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:55.461635Z",
     "start_time": "2021-04-13T14:38:55.457230Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_stations(bounds, stations):\n",
    "    total_points = MultiPoint([Point(x,y) for x, y in stations[['X', 'Y']].to_numpy()])\n",
    "    intersection = bounds.buffer(AREA_OF_INFLUENCE).intersection(total_points)\n",
    "    \n",
    "    return stations[[ intersection.contains(point) for point in total_points]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Distance Weighting interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:58.209269Z",
     "start_time": "2021-04-13T14:38:58.202597Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_basic_interpolation(shape, stations, field_value, offset = (0,0)):\n",
    "    station_pixels = [[pixel[0], pixel[1]] for pixel in stations['pixel'].to_numpy()]\n",
    "    \n",
    "    # Get an array where each position represents pixel coordinates\n",
    "    tile_pixels = np.indices(shape).transpose(1,2,0).reshape(shape[0]*shape[1], 2) + offset\n",
    "    dist = distance_matrix(station_pixels, tile_pixels)\n",
    "    weights = np.where(dist == 0, np.finfo('float32').max, 1.0 / dist )\n",
    "    weights /=  weights.sum(axis=0)\n",
    "    \n",
    "    return np.dot(weights.T, stations[field_value].to_numpy()).reshape(shape).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate temperatures from a subset of the tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:59.031150Z",
     "start_time": "2021-04-13T14:38:59.005158Z"
    }
   },
   "outputs": [],
   "source": [
    "def radiation_interpolation(obj, block_x, block_y, splits, storage):\n",
    "    tile_key = os.path.basename(obj.key)\n",
    "    tile_id, _ = os.path.splitext(tile_key)\n",
    "    \n",
    "    with rasterio.open(obj.data_stream) as src:\n",
    "        transform = src.transform\n",
    "        \n",
    "        # Compute working window\n",
    "        step_w = src.width / splits\n",
    "        step_h = src.height / splits\n",
    "        \n",
    "        offset_h = round(step_h * block_x)\n",
    "        offset_w = round(step_w * block_y)\n",
    "        \n",
    "        profile = src.profile\n",
    "        width = math.ceil(step_w * (block_y + 1) - offset_w)\n",
    "        height = math.ceil(step_h * (block_x + 1) - offset_h)\n",
    "        \n",
    "        profile.update(width=width)\n",
    "        profile.update(height=height)\n",
    "        \n",
    "        window = Window(offset_w, offset_h, width, height)\n",
    "        \n",
    "        with rasterio.open('input', 'w', **profile) as dest:\n",
    "            dest.write(src.read(window=window))\n",
    "        \n",
    "    # Stores global irradiation at \"output\", it also returns extraterrestrial irradiation\n",
    "    extraterrestrial_irradiation = compute_solar_irradiation('input', 'output')\n",
    "        \n",
    "    # Create and store a raster with extraterrestrial_irradiation\n",
    "    with rasterio.open('extr', 'w', **profile) as dest:\n",
    "        data = np.full((height, width), extraterrestrial_irradiation, dtype='float32')\n",
    "        dest.write(data, 1)\n",
    "        \n",
    "    out_key = os.path.join('tmp', 'extrad', tile_id, f'chunk_{block_x}-{block_y}') + '.tif'\n",
    "    with open('extr', 'rb') as out_file:\n",
    "        storage.put_object(BUCKET, out_key, out_file)\n",
    "    \n",
    "    out_key = os.path.join('tmp', 'rad', tile_id, f'chunk_{block_x}-{block_y}') + '.tif'\n",
    "    with open('output', 'rb') as out_file:\n",
    "        storage.put_object(BUCKET, out_key, out_file)\n",
    "    \n",
    "    return out_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:39:01.538202Z",
     "start_time": "2021-04-13T14:39:01.521080Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_interpolation(obj, block_x, block_y, splits, data_field, storage):    \n",
    "    tile_key = os.path.basename(obj.key)\n",
    "    tile_id, _ = os.path.splitext(tile_key)\n",
    "          \n",
    "    siam_stream = storage.get_object(BUCKET, 'siam.csv', stream=True)\n",
    "    siam = pd.read_csv(siam_stream)\n",
    "    \n",
    "    with rasterio.open(obj.data_stream) as src:\n",
    "        transform = src.transform\n",
    "        \n",
    "        # Compute working window\n",
    "        step_w = src.width / splits\n",
    "        step_h = src.height / splits\n",
    "        \n",
    "        offset_h = round(step_h * block_x)\n",
    "        offset_w = round(step_w * block_y)\n",
    "        \n",
    "        profile = src.profile\n",
    "        \n",
    "        width = math.ceil(step_w * (block_y + 1) - offset_w)\n",
    "        height = math.ceil(step_h * (block_x + 1) - offset_h)\n",
    "        \n",
    "        profile.update(width=width)\n",
    "        profile.update(height=height)\n",
    "        \n",
    "        window = Window(offset_w,offset_h, width, height)\n",
    "        \n",
    "        # Filter desired stations\n",
    "        bounding_rect = box(src.bounds.left, src.bounds.top, src.bounds.right, src.bounds.bottom)\n",
    "        filtered = pd.DataFrame(filter_stations(bounding_rect, siam))\n",
    "        filtered['pixel'] = filtered.apply(\n",
    "            lambda station: rasterio.transform.rowcol(transform, station['X'], station['Y']), axis=1)\n",
    "        \n",
    "        # Interpolate and write results \n",
    "        with rasterio.open('output', 'w', **profile) as dest:\n",
    "            if data_field == 'temp':\n",
    "                elevations = src.read(1, window=window) # Get elevations content\n",
    "                interpolation = compute_basic_interpolation(elevations.shape, filtered,\n",
    "                                                            'tdet', (offset_h, offset_w))\n",
    "                interpolation += r * (elevations - zdet)\n",
    "                dest.write(np.where(elevations == src.nodata, np.nan, interpolation), 1)\n",
    "            else:\n",
    "                interpolation = compute_basic_interpolation((height, width), \n",
    "                                                            filtered, \n",
    "                                                            'hr' if data_field == 'humi' else 'v', \n",
    "                                                            (offset_h, offset_w))\n",
    "                dest.write(interpolation, 1)\n",
    "\n",
    "    # Export results to storage\n",
    "    out_key = os.path.join('tmp', data_field, tile_id, 'chunk_{}-{}'.format(block_x, block_y)) + '.tif'\n",
    "    with open('output', 'rb') as output_file:\n",
    "        storage.put_object(BUCKET, out_key, output_file)\n",
    "    \n",
    "    return out_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lithops serverless computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:39:28.155159Z",
     "start_time": "2021-04-13T14:39:28.150797Z"
    }
   },
   "outputs": [],
   "source": [
    "iterdata = [(os.path.join('localhost://', DATA_BUCKET, tile), i, j) for i in range(SPLITS) for j in range(SPLITS) for tile in dtm_geotiff_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:39:28.850404Z",
     "start_time": "2021-04-13T14:39:28.812552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('localhost://geospatial-usecase/DTMs/geotiff/PNOA_MDT05_ETRS89_HU31_0359_LID.tiff',\n",
      "  0,\n",
      "  0),\n",
      " ('localhost://geospatial-usecase/DTMs/geotiff/PNOA_MDT05_ETRS89_HU31_0359_LID.tiff',\n",
      "  0,\n",
      "  1),\n",
      " ('localhost://geospatial-usecase/DTMs/geotiff/PNOA_MDT05_ETRS89_HU31_0359_LID.tiff',\n",
      "  1,\n",
      "  0),\n",
      " ('localhost://geospatial-usecase/DTMs/geotiff/PNOA_MDT05_ETRS89_HU31_0359_LID.tiff',\n",
      "  1,\n",
      "  1)]\n",
      "Total functions: 1 tiles * (2^2) splits * 4 calculations = 16\n"
     ]
    }
   ],
   "source": [
    "pprint(iterdata)\n",
    "print('Total functions: {} tiles * ({}^2) splits * 4 calculations = {}'.format(\n",
    "    len(tiles), SPLITS, len(iterdata) * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T06:56:29.270356Z",
     "start_time": "2021-04-08T06:56:27.066344Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:41:33,732 [INFO] lithops.invokers -- ExecutorID c3b6f0-1 | JobID M006 - Selected Runtime: python \n",
      "2022-06-02 08:41:33,739 [INFO] lithops.invokers -- ExecutorID c3b6f0-1 | JobID M006 - Starting function invocation: radiation_interpolation() - Total: 4 activations\n",
      "2022-06-02 08:41:33,740 [INFO] lithops.invokers -- ExecutorID c3b6f0-1 | JobID M006 - View execution logs at /tmp/lithops/logs/c3b6f0-1-M006.log\n"
     ]
    }
   ],
   "source": [
    "fs1 = fexec.map(radiation_interpolation, iterdata, extra_args=(SPLITS,))\n",
    "# fs2 = fexec.map(map_interpolation, iterdata, extra_args=(SPLITS, 'temp'))\n",
    "# fs3 = fexec.map(map_interpolation, iterdata, extra_args=(SPLITS, 'humi'))\n",
    "# fs4 = fexec.map(map_interpolation, iterdata, extra_args=(SPLITS, 'wind'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:41:34,702 [INFO] lithops.wait -- ExecutorID c3b6f0-1 - Getting results from 4 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa763648929f4df69a48ec7323780716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:41:35,778 [INFO] lithops.executors -- ExecutorID c3b6f0-1 - Cleaning temporary data\n"
     ]
    },
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "input: TIFFReadDirectory:Failed to read directory at offset 14733392",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res1 \u001b[38;5;241m=\u001b[39m \u001b[43mfexec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/executors.py:466\u001b[0m, in \u001b[0;36mFunctionExecutor.get_result\u001b[0;34m(self, fs, throw_except, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    451\u001b[0m                fs: Optional[Union[ResponseFuture, FuturesList, List[ResponseFuture]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    452\u001b[0m                throw_except: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    453\u001b[0m                timeout: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    454\u001b[0m                threadpool_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m THREADPOOL_SIZE,\n\u001b[1;32m    455\u001b[0m                wait_dur_sec: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m WAIT_DUR_SEC):\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    For getting the results from all function activations\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    :return: The result of the future/s\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m     fs_done, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mthreadpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreadpool_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mwait_dur_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_dur_sec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    471\u001b[0m     fs_done \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs_done \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mfutures \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_produce_output]\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/executors.py:439\u001b[0m, in \u001b[0;36mFunctionExecutor.wait\u001b[0;34m(self, fs, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_handler\u001b[38;5;241m.\u001b[39mclear(present_jobs)\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean(clean_cloudobjects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_results:\n\u001b[1;32m    442\u001b[0m     fs_done \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone]\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/executors.py:415\u001b[0m, in \u001b[0;36mFunctionExecutor.wait\u001b[0;34m(self, fs, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# Start waiting for results\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m         \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m         \u001b[49m\u001b[43mjob_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdownload_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m         \u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m         \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_when\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m         \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m         \u001b[49m\u001b[43mthreadpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreadpool_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m         \u001b[49m\u001b[43mwait_dur_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_dur_sec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_cleaner \u001b[38;5;129;01mand\u001b[39;00m return_when \u001b[38;5;241m==\u001b[39m ALL_COMPLETED:\n\u001b[1;32m    426\u001b[0m         present_jobs \u001b[38;5;241m=\u001b[39m {f\u001b[38;5;241m.\u001b[39mjob_key \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures}\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/wait.py:156\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, internal_storage, job_monitor, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_unix_system():\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/wait.py:137\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, internal_storage, job_monitor, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _check_done(fs, return_when, download_results):\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m executor_data \u001b[38;5;129;01min\u001b[39;00m executors_data:\n\u001b[0;32m--> 137\u001b[0m                 new_data \u001b[38;5;241m=\u001b[39m \u001b[43m_get_executor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mdownload_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mthreadpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreadpool_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_data \u001b[38;5;28;01melse\u001b[39;00m sleep_sec)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/wait.py:277\u001b[0m, in \u001b[0;36m_get_executor_data\u001b[0;34m(fs, exec_data, download_results, throw_except, threadpool_size, pbar)\u001b[0m\n\u001b[1;32m    275\u001b[0m pool \u001b[38;5;241m=\u001b[39m cf\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mthreadpool_size)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_results:\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs_to_wait_on\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mlist\u001b[39m(pool\u001b[38;5;241m.\u001b[39mmap(get_status, fs_to_wait_on))\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/wait.py:270\u001b[0m, in \u001b[0;36m_get_executor_data.<locals>.get_result\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(f):\n\u001b[0;32m--> 270\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexec_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/future.py:321\u001b[0m, in \u001b[0;36mResponseFuture.result\u001b[0;34m(self, throw_except, internal_storage)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_storage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     internal_storage \u001b[38;5;241m=\u001b[39m InternalStorage(storage_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_config)\n\u001b[0;32m--> 321\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_val\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/future.py:256\u001b[0m, in \u001b[0;36mResponseFuture.status\u001b[0;34m(self, throw_except, internal_storage, check_only)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m throw_except:\n\u001b[1;32m    255\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexcepthook \u001b[38;5;241m=\u001b[39m exception_hook\n\u001b[0;32m--> 256\u001b[0m     \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(msg1)\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/six.py:718\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    716\u001b[0m         value \u001b[38;5;241m=\u001b[39m tp()\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/lithops/lithops/worker/jobrunner.py:228\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------- FUNCTION LOG ----------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    227\u001b[0m function_start_tstamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 228\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n\u001b[1;32m    229\u001b[0m function_end_tstamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36mradiation_interpolation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     profile\u001b[38;5;241m.\u001b[39mupdate(height\u001b[38;5;241m=\u001b[39mheight)\n\u001b[1;32m     22\u001b[0m     window \u001b[38;5;241m=\u001b[39m Window(offset_w, offset_h, width, height)\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprofile) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[1;32m     25\u001b[0m         dest\u001b[38;5;241m.\u001b[39mwrite(src\u001b[38;5;241m.\u001b[39mread(window\u001b[38;5;241m=\u001b[39mwindow))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Stores global irradiation at \"output\", it also returns extraterrestrial irradiation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/rasterio/env.py:437\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    434\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/rasterio/__init__.py:230\u001b[0m, in \u001b[0;36mopen\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m writer \u001b[38;5;241m=\u001b[39m get_writer_for_driver(driver)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     s \u001b[38;5;241m=\u001b[39m writer(path, mode, driver\u001b[38;5;241m=\u001b[39mdriver,\n\u001b[1;32m    231\u001b[0m                width\u001b[38;5;241m=\u001b[39mwidth, height\u001b[38;5;241m=\u001b[39mheight,\n\u001b[1;32m    232\u001b[0m                count\u001b[38;5;241m=\u001b[39mcount, crs\u001b[38;5;241m=\u001b[39mcrs,\n\u001b[1;32m    233\u001b[0m                transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[1;32m    234\u001b[0m                dtype\u001b[38;5;241m=\u001b[39mdtype, nodata\u001b[38;5;241m=\u001b[39mnodata,\n\u001b[1;32m    235\u001b[0m                sharing\u001b[38;5;241m=\u001b[39msharing,\n\u001b[1;32m    236\u001b[0m                \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DriverCapabilityError(\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriter does not exist for driver: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(driver)\n\u001b[1;32m    240\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_io.pyx:1122\u001b[0m, in \u001b[0;36mrasterio._io.DatasetWriterBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_io.pyx:70\u001b[0m, in \u001b[0;36mrasterio._io._delete_dataset_if_exists\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_shim.pyx:78\u001b[0m, in \u001b[0;36mrasterio._shim.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:216\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m: input: TIFFReadDirectory:Failed to read directory at offset 14733392"
     ]
    }
   ],
   "source": [
    "res1 = fexec.get_result(fs=fs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_flat = [fs for sublist in [fs1, fs2, fs3, fs4] for fs in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:40:38,130 [INFO] lithops.wait -- ExecutorID c3b6f0-1 - Getting results from 16 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde8d63719614b539b7561972726a22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 08:40:38,164 [INFO] lithops.executors -- ExecutorID c3b6f0-1 - Cleaning temporary data\n"
     ]
    },
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "input: TIFFReadDirectory:Failed to read directory at offset 14733392",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfexec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs_flat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/executors.py:466\u001b[0m, in \u001b[0;36mFunctionExecutor.get_result\u001b[0;34m(self, fs, throw_except, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    451\u001b[0m                fs: Optional[Union[ResponseFuture, FuturesList, List[ResponseFuture]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    452\u001b[0m                throw_except: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    453\u001b[0m                timeout: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    454\u001b[0m                threadpool_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m THREADPOOL_SIZE,\n\u001b[1;32m    455\u001b[0m                wait_dur_sec: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m WAIT_DUR_SEC):\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    For getting the results from all function activations\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    :return: The result of the future/s\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m     fs_done, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mthreadpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreadpool_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mwait_dur_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_dur_sec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    471\u001b[0m     fs_done \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs_done \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mfutures \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_produce_output]\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/executors.py:439\u001b[0m, in \u001b[0;36mFunctionExecutor.wait\u001b[0;34m(self, fs, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_handler\u001b[38;5;241m.\u001b[39mclear(present_jobs)\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean(clean_cloudobjects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_results:\n\u001b[1;32m    442\u001b[0m     fs_done \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone]\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/executors.py:415\u001b[0m, in \u001b[0;36mFunctionExecutor.wait\u001b[0;34m(self, fs, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# Start waiting for results\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m         \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m         \u001b[49m\u001b[43mjob_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdownload_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m         \u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m         \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_when\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m         \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m         \u001b[49m\u001b[43mthreadpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreadpool_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m         \u001b[49m\u001b[43mwait_dur_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_dur_sec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_cleaner \u001b[38;5;129;01mand\u001b[39;00m return_when \u001b[38;5;241m==\u001b[39m ALL_COMPLETED:\n\u001b[1;32m    426\u001b[0m         present_jobs \u001b[38;5;241m=\u001b[39m {f\u001b[38;5;241m.\u001b[39mjob_key \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures}\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/wait.py:156\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, internal_storage, job_monitor, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_unix_system():\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/wait.py:137\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, internal_storage, job_monitor, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _check_done(fs, return_when, download_results):\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m executor_data \u001b[38;5;129;01min\u001b[39;00m executors_data:\n\u001b[0;32m--> 137\u001b[0m                 new_data \u001b[38;5;241m=\u001b[39m \u001b[43m_get_executor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mdownload_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mthreadpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreadpool_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_data \u001b[38;5;28;01melse\u001b[39;00m sleep_sec)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/wait.py:277\u001b[0m, in \u001b[0;36m_get_executor_data\u001b[0;34m(fs, exec_data, download_results, throw_except, threadpool_size, pbar)\u001b[0m\n\u001b[1;32m    275\u001b[0m pool \u001b[38;5;241m=\u001b[39m cf\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mthreadpool_size)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_results:\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs_to_wait_on\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mlist\u001b[39m(pool\u001b[38;5;241m.\u001b[39mmap(get_status, fs_to_wait_on))\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/wait.py:270\u001b[0m, in \u001b[0;36m_get_executor_data.<locals>.get_result\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(f):\n\u001b[0;32m--> 270\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexec_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/future.py:321\u001b[0m, in \u001b[0;36mResponseFuture.result\u001b[0;34m(self, throw_except, internal_storage)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_storage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     internal_storage \u001b[38;5;241m=\u001b[39m InternalStorage(storage_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_config)\n\u001b[0;32m--> 321\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_val\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/lithops/future.py:256\u001b[0m, in \u001b[0;36mResponseFuture.status\u001b[0;34m(self, throw_except, internal_storage, check_only)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m throw_except:\n\u001b[1;32m    255\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexcepthook \u001b[38;5;241m=\u001b[39m exception_hook\n\u001b[0;32m--> 256\u001b[0m     \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(msg1)\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/six.py:718\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    716\u001b[0m         value \u001b[38;5;241m=\u001b[39m tp()\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/lithops/lithops/worker/jobrunner.py:228\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------- FUNCTION LOG ----------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    227\u001b[0m function_start_tstamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 228\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n\u001b[1;32m    229\u001b[0m function_end_tstamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36mradiation_interpolation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     profile\u001b[38;5;241m.\u001b[39mupdate(height\u001b[38;5;241m=\u001b[39mheight)\n\u001b[1;32m     22\u001b[0m     window \u001b[38;5;241m=\u001b[39m Window(offset_w, offset_h, width, height)\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprofile) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[1;32m     25\u001b[0m         dest\u001b[38;5;241m.\u001b[39mwrite(src\u001b[38;5;241m.\u001b[39mread(window\u001b[38;5;241m=\u001b[39mwindow))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Stores global irradiation at \"output\", it also returns extraterrestrial irradiation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/rasterio/env.py:437\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    434\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.9/site-packages/rasterio/__init__.py:230\u001b[0m, in \u001b[0;36mopen\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m writer \u001b[38;5;241m=\u001b[39m get_writer_for_driver(driver)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     s \u001b[38;5;241m=\u001b[39m writer(path, mode, driver\u001b[38;5;241m=\u001b[39mdriver,\n\u001b[1;32m    231\u001b[0m                width\u001b[38;5;241m=\u001b[39mwidth, height\u001b[38;5;241m=\u001b[39mheight,\n\u001b[1;32m    232\u001b[0m                count\u001b[38;5;241m=\u001b[39mcount, crs\u001b[38;5;241m=\u001b[39mcrs,\n\u001b[1;32m    233\u001b[0m                transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[1;32m    234\u001b[0m                dtype\u001b[38;5;241m=\u001b[39mdtype, nodata\u001b[38;5;241m=\u001b[39mnodata,\n\u001b[1;32m    235\u001b[0m                sharing\u001b[38;5;241m=\u001b[39msharing,\n\u001b[1;32m    236\u001b[0m                \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DriverCapabilityError(\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriter does not exist for driver: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(driver)\n\u001b[1;32m    240\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_io.pyx:1122\u001b[0m, in \u001b[0;36mrasterio._io.DatasetWriterBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_io.pyx:70\u001b[0m, in \u001b[0;36mrasterio._io._delete_dataset_if_exists\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_shim.pyx:78\u001b[0m, in \u001b[0;36mrasterio._shim.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:216\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m: input: TIFFReadDirectory:Failed to read directory at offset 14733392"
     ]
    }
   ],
   "source": [
    "res = fexec.get_result(fs=fs_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPIs (Interpolation)\n",
    "\n",
    "[Skip KPI section](#(End-of-KPI-section---Interpolation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:02:05.040966Z",
     "start_time": "2021-04-08T07:02:04.321663Z"
    }
   },
   "outputs": [],
   "source": [
    "fexec.plot(dst=\"plots/interpolation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:02:45.854968Z",
     "start_time": "2021-04-08T07:02:45.848629Z"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"plots/interpolation_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:02:54.046898Z",
     "start_time": "2021-04-08T07:02:54.036980Z"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"plots/interpolation_timeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of .tif files being processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:03:29.258771Z",
     "start_time": "2021-04-08T07:03:29.255051Z"
    }
   },
   "outputs": [],
   "source": [
    "mdts_gtiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total size accounting that files were repeatedly processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:03:33.021230Z",
     "start_time": "2021-04-08T07:03:32.728522Z"
    }
   },
   "outputs": [],
   "source": [
    "data_size = sum(obj[\"Size\"] for obj in cloud_storage.list_objects(BUCKET) if obj[\"Key\"] in mdts_gtiff)\n",
    "data_size *= 4  # Each file was processed 4 times\n",
    "\n",
    "print(f\"Data size: {data_size / 1024**2} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KPI: Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:03:37.464531Z",
     "start_time": "2021-04-08T07:03:37.441706Z"
    }
   },
   "outputs": [],
   "source": [
    "fexec.job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:03:51.895064Z",
     "start_time": "2021-04-08T07:03:51.879123Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(fexec.log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:03:39.286038Z",
     "start_time": "2021-04-08T07:03:39.276118Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_interpolation = get_process_cost(fexec)\n",
    "print(f\"The experiment cost ${cost_interpolation:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KPI: Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:05:08.953755Z",
     "start_time": "2021-04-08T07:05:08.931643Z"
    }
   },
   "outputs": [],
   "source": [
    "tstamps = set()\n",
    "for future in fexec.futures:\n",
    "    for key in future.stats.keys():\n",
    "        if key.endswith(\"tstamp\"):\n",
    "            tstamps.add(future.stats[key])\n",
    "            \n",
    "duration = max(tstamps) - min(tstamps)\n",
    "print(\"Duration: \" + str(duration) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:05:11.960461Z",
     "start_time": "2021-04-08T07:05:11.953193Z"
    }
   },
   "outputs": [],
   "source": [
    "throughput_interpolation = data_size / duration  # Bytes/second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:05:13.342171Z",
     "start_time": "2021-04-08T07:05:13.338300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Throughput: {throughput_interpolation / 1024**2} MiB/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KPI: Speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we compare the execution speed of a sample process performed in last section, using different amounts of parallel workers, in order to test the scalability of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:39:50.231357Z",
     "start_time": "2021-04-13T14:39:50.225667Z"
    }
   },
   "outputs": [],
   "source": [
    "parallel_workers = [12, 24, 48, 72]\n",
    "experiment_duration = dict.fromkeys(parallel_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform experiment several times and save duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:41:52.721071Z",
     "start_time": "2021-04-13T14:40:15.651918Z"
    }
   },
   "outputs": [],
   "source": [
    "for option in parallel_workers:\n",
    "    fexec = lithops.FunctionExecutor(\n",
    "        backend=COMPUTE_BACKEND, \n",
    "        storage=STORAGE_BACKEND,\n",
    "        runtime=RUNTIME,\n",
    "        workers=option, # Tells lithops to work w/only this number of concurrent workers\n",
    "        log_level=\"DEBUG\"\n",
    "    )\n",
    "    fexec.map(\n",
    "        map_interpolation, iterdata, extra_args=(SPLITS,'temp'), runtime_memory=2048\n",
    "    )\n",
    "    fexec.get_result()\n",
    "    \n",
    "    tstamps = set()\n",
    "    for future in fexec.futures:\n",
    "        for key in future.stats.keys():\n",
    "            if key.endswith(\"tstamp\"):\n",
    "                tstamps.add(future.stats[key])\n",
    "    duration = max(tstamps) - min(tstamps)\n",
    "    experiment_duration[option] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:41:55.994144Z",
     "start_time": "2021-04-13T14:41:55.989057Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization of per-worker performance relative to first experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot represents two lines:\n",
    "- **Ideal speedup**: theoretical best speedup - scenario where a 2x increment in workers results in 1/2 execution time, a 4x increment in workers results in a 1/4 execution time, etc.\n",
    "- **Lithops speedup**: actual speedup that results from the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T15:09:52.888690Z",
     "start_time": "2021-04-13T15:09:52.723516Z"
    }
   },
   "outputs": [],
   "source": [
    "duration = list(experiment_duration.values())\n",
    "theoretical_best_speedup = [(1 - parallel_workers[0] / parallel_workers[i]) * 100 for i in range(0, len(parallel_workers))]\n",
    "actual_speedup = [(1 - duration[i] / duration[0]) * 100 for i in range(0, len(duration))]\n",
    "\n",
    "plt.plot(\n",
    "    parallel_workers,\n",
    "    theoretical_best_speedup\n",
    ")\n",
    "plt.plot(\n",
    "    parallel_workers,\n",
    "    actual_speedup\n",
    ")\n",
    "plt.xlabel(\"Number of workers\")\n",
    "plt.ylabel(\"% time reduced, relative to first experiment\")\n",
    "plt.legend([\"Ideal speedup\", \"Lithops speedup (this experiment)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:11:22.584754Z",
     "start_time": "2021-04-08T07:11:22.577217Z"
    }
   },
   "outputs": [],
   "source": [
    "fexec.futures = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:10:54.929461Z",
     "start_time": "2021-04-08T07:10:54.917364Z"
    }
   },
   "source": [
    "###### (End of KPI section - Interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join split subsets into a tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:21:21.921233Z",
     "start_time": "2021-04-08T07:21:21.911497Z"
    }
   },
   "outputs": [],
   "source": [
    "def gather_blocks(tile, splits, data_field, storage):\n",
    "\n",
    "    from rasterio.windows import Window\n",
    "    \n",
    "    # Get width and height from original tile\n",
    "    with rasterio.open(storage.get_object(bucket=BUCKET, key=f'MDT/{tile}.tif', stream=True)) as og:\n",
    "        height = og.profile['height']\n",
    "        width = og.profile['width']\n",
    "    \n",
    "    chunk_tiles = storage.list_keys(bucket=BUCKET, prefix=f'tmp/{data_field}/{tile}/chunk')\n",
    "        \n",
    "    # Open first object to obtain profile metadata\n",
    "    with rasterio.open(storage.get_object(bucket=BUCKET, key=chunk_tiles[0], stream=True)) as src:\n",
    "        profile = src.profile\n",
    "        profile.update(width=width)\n",
    "        profile.update(height=height)\n",
    "\n",
    "    # Iterate each object and print its block into the destination file\n",
    "    with rasterio.open(\"output\", \"w\", **profile) as dest: \n",
    "        for chunk in chunk_tiles:\n",
    "            j, i = os.path.splitext(os.path.basename(chunk))[0].rsplit('_')[1].split('-')\n",
    "            j, i = int(j), int(i)\n",
    "            with rasterio.open(storage.get_object(bucket=BUCKET, key=chunk, stream=True)) as src:\n",
    "                step_w = math.floor(width / splits)\n",
    "                step_h = math.floor(height / splits)\n",
    "                curr_window = Window(round(step_w * i), round(step_h * j), src.width, src.height)\n",
    "                content = src.read(1)\n",
    "                dest.write(content, 1, window=curr_window)\n",
    "            # storage.delete_object(bucket=BUCKET, key=chunk)\n",
    "    \n",
    "    output_key = os.path.join('tmp', data_field, tile, '_'.join([tile, data_field.upper()+'.tif']))\n",
    "    with open('output', 'rb') as out_file:\n",
    "        storage.put_object(bucket=BUCKET, key=output_key, body=out_file)  \n",
    "    \n",
    "    return output_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine previous split subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:21:43.580625Z",
     "start_time": "2021-04-08T07:21:43.180508Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fexec.map(gather_blocks, tiles, extra_args=(SPLITS, 'extrad'), runtime_memory=2048)\n",
    "\n",
    "fexec.map(gather_blocks, tiles, extra_args=(SPLITS, 'humi'), runtime_memory=2048)\n",
    "\n",
    "fexec.map(gather_blocks, tiles, extra_args=(SPLITS, 'rad'), runtime_memory=2048)\n",
    "\n",
    "fexec.map(gather_blocks, tiles, extra_args=(SPLITS, 'temp'), runtime_memory=2048)\n",
    "\n",
    "fexec.map(gather_blocks, tiles, extra_args=(SPLITS, 'wind'), runtime_memory=2048)\n",
    "\n",
    "out_combined = fexec.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPIs (Gather blocks)\n",
    "\n",
    "[Skip KPI section](#(End-of-KPI-section---Gather-blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:23:42.594365Z",
     "start_time": "2021-04-08T07:23:42.135958Z"
    }
   },
   "outputs": [],
   "source": [
    "fexec.plot(dst=\"plots/gather_blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:23:44.168346Z",
     "start_time": "2021-04-08T07:23:44.162948Z"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"plots/gather_blocks_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T07:23:45.856957Z",
     "start_time": "2021-04-08T07:23:45.840851Z"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"plots/gather_blocks_timeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:17:25.463278Z",
     "start_time": "2021-04-08T08:17:25.458630Z"
    }
   },
   "outputs": [],
   "source": [
    "mdts_gtiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:17:30.709533Z",
     "start_time": "2021-04-08T08:17:29.875330Z"
    }
   },
   "outputs": [],
   "source": [
    "data_size = sum(obj[\"Size\"] for obj in cloud_storage.list_objects(BUCKET) if obj[\"Key\"] in mdts_gtiff)\n",
    "data_size *= 4  # Each file was processed 4 times\n",
    "\n",
    "print(f\"Data size: {data_size / 1024**2} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KPI: Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:18:54.513927Z",
     "start_time": "2021-04-08T08:18:54.486157Z"
    }
   },
   "outputs": [],
   "source": [
    "fexec.job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:19:02.264749Z",
     "start_time": "2021-04-08T08:19:02.236457Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(fexec.log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:21:09.051314Z",
     "start_time": "2021-04-08T08:21:09.031537Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_gather_blocks = get_process_cost(fexec)\n",
    "print(f\"The experiment cost ${cost_gather_blocks:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KPI: Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:19:57.208334Z",
     "start_time": "2021-04-08T08:19:57.189780Z"
    }
   },
   "outputs": [],
   "source": [
    "tstamps = set()\n",
    "for future in fexec.futures:\n",
    "    for key in future.stats.keys():\n",
    "        if key.endswith(\"tstamp\"):\n",
    "            tstamps.add(future.stats[key])\n",
    "            \n",
    "duration = max(tstamps) - min(tstamps)\n",
    "print(\"Duration: \" + str(duration) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:21:20.407233Z",
     "start_time": "2021-04-08T08:21:20.404210Z"
    }
   },
   "outputs": [],
   "source": [
    "throughput_gather_blocks = data_size / duration  # Bytes/second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:21:35.726076Z",
     "start_time": "2021-04-08T08:21:35.720504Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Throughput: {throughput_gather_blocks / 1024**2} MiB/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:22:57.849484Z",
     "start_time": "2021-04-08T08:22:57.844112Z"
    }
   },
   "outputs": [],
   "source": [
    "fexec.futures = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (End of KPI section - Gather blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of potential evaporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:51.493674Z",
     "start_time": "2021-04-13T16:57:51.485032Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_crop_evapotranspiration(temperatures,\n",
    "                                    humidities,\n",
    "                                    wind_speeds,\n",
    "                                    external_radiations,\n",
    "                                    global_radiations,\n",
    "                                    KCs):\n",
    "    gamma = 0.665*101.3/1000\n",
    "    eSat = 0.6108 * np.exp((17.27*temperatures)/(temperatures+237.3))\n",
    "    delta = 4098 * eSat / np.power((temperatures + 237.3),2)\n",
    "    eA = np.where(humidities < 0, 0, eSat * humidities / 100)     # Avoid sqrt of a negative number\n",
    "    T4 = 4.903 * np.power((273.3 + temperatures),4)/1000000000\n",
    "    rSrS0 = global_radiations/(external_radiations * 0.75)\n",
    "    rN = 0.8* global_radiations-T4*(0.34-0.14*np.sqrt(eA))*((1.35*rSrS0)-0.35)\n",
    "    den = delta + gamma *(1 + 0.34* wind_speeds)\n",
    "    tRad = 0.408 * delta * rN / den\n",
    "    tAdv = gamma * (900/(temperatures+273))*wind_speeds * (eSat - eA)/den\n",
    "    return ((tRad + tAdv) * 7 * KCs).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:52.760441Z",
     "start_time": "2021-04-13T16:57:52.753812Z"
    }
   },
   "outputs": [],
   "source": [
    "vineyard = ['VI', 'VO', 'VF', 'FV', 'CV' ]\n",
    "olive_grove = ['OV', 'VO', 'OF', 'FL', 'OC']\n",
    "fruit = ['FY', 'VF', 'OF', 'FF', 'CF']\n",
    "nuts = ['FS', 'FV', 'FL', 'FF', 'CS' ]\n",
    "citrus = ['CI', 'CV', 'OC', 'CF', 'CS' ]\n",
    "\n",
    "def get_kc(feature):\n",
    "    \n",
    "    # TODO: Get more precise values of Kc\n",
    "    sigpac_use = feature['properties']['uso_sigpac']\n",
    "    if sigpac_use in vineyard:\n",
    "        # Grapes for wine - 0.3, 0.7, 0.45\n",
    "        return 0.7  \n",
    "    if sigpac_use in olive_grove:\n",
    "        # Olive grove - ini: 0.65, med: 0.7, end: 0.7\n",
    "        return 0.7 \n",
    "    if sigpac_use in fruit:\n",
    "        # Apples, Cherries, Pears - 0.45, 0.95, 0.7\n",
    "        return 0.95\n",
    "    if sigpac_use in nuts:\n",
    "        # Almonds - 0.4, 0.9, 0.65\n",
    "        return 0.9\n",
    "    if sigpac_use in citrus:\n",
    "        # Citrus, without ground coverage - 0.7, 0.65, 0.7\n",
    "        return 0.65\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:54.250115Z",
     "start_time": "2021-04-13T16:57:54.243932Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_geometry_window(src, geom_bounds):\n",
    "    left, bottom, right, top = geom_bounds\n",
    "    src_left, src_bottom, src_right, src_top = src.bounds\n",
    "    window = src.window(max(left,src_left), max(bottom,src_bottom), min(right,src_right), min(top,src_top))\n",
    "    window_floored = window.round_offsets(op='floor', pixel_precision=3)\n",
    "    w = math.ceil(window.width + window.col_off - window_floored.col_off)\n",
    "    h = math.ceil(window.height + window.row_off - window_floored.row_off)\n",
    "    return Window(window_floored.col_off, window_floored.row_off, w, h)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:57.781920Z",
     "start_time": "2021-04-13T16:57:57.770029Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_evapotranspiration_by_shape(tem, hum, win, rad, extrad, dst):\n",
    "    \n",
    "    import fiona\n",
    "    from shapely.geometry import shape, box\n",
    "    from rasterio import features\n",
    "    \n",
    "    non_arable_land = ['AG', 'CA', 'ED', 'FO', 'IM', 'PA', 'PR', 'ZU', 'ZV']\n",
    "    \n",
    "    with fiona.open('zip://shape.zip') as shape_src:\n",
    "        for feature in shape_src.filter(bbox=tem.bounds):\n",
    "            KC = get_kc(feature) \n",
    "            if KC is not None:   \n",
    "                geom = shape(feature['geometry'])  \n",
    "                window = get_geometry_window(tem, geom.bounds)              \n",
    "                win_transform = rasterio.windows.transform(window, tem.transform)\n",
    "                # Convert shape to raster matrix\n",
    "                image = features.rasterize([geom],\n",
    "                                           out_shape=(window.height, window.width),\n",
    "                                           transform = win_transform,\n",
    "                                           fill = 0,\n",
    "                                           default_value = 1).astype('bool')\n",
    "                # Get values to compute evapotranspiration\n",
    "                temperatures = tem.read(1, window=window)\n",
    "                humidities = hum.read(1, window=window)\n",
    "                wind_speeds = win.read(1, window=window)\n",
    "                # Convert from W to MJ (0.0036)\n",
    "                global_radiations = rad.read(1, window=window) * 0.0036\n",
    "                external_radiations = extrad.read(1, window=window) * 0.0036\n",
    "                KCs = np.full(temperatures.shape, KC)\n",
    "                # TODO: compute external radiation\n",
    "                #external_radiations = np.full(temperatures.shape, 14)\n",
    "                # TODO: compute global radiation\n",
    "                # global_radiations = np.full(temperatures.shape, 10)\n",
    "                etc = compute_crop_evapotranspiration(\n",
    "                        temperatures,\n",
    "                        humidities,\n",
    "                        wind_speeds,\n",
    "                        external_radiations,\n",
    "                        global_radiations,\n",
    "                        KCs\n",
    "                )\n",
    "                etc[temperatures == tem.nodata] = dst.nodata\n",
    "                etc[np.logical_not(image)] = dst.nodata\n",
    "                dst.write(etc + dst.read(1, window=window), 1, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:59.216824Z",
     "start_time": "2021-04-13T16:57:59.207435Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_global_evapotranspiration(tem, hum, win, rad, extrad, dst):    \n",
    "    for ji, window in tem.block_windows(1):\n",
    "        bounds = rasterio.windows.bounds(window, tem.transform)\n",
    "        temperatures = tem.read(1, window=window)\n",
    "        humidities = hum.read(1, window=window)\n",
    "        wind_speeds = win.read(1, window=window)\n",
    "         # Convert from W to MJ (0.0036)\n",
    "        global_radiations = rad.read(1, window=window) * 0.0036\n",
    "        external_radiations = extrad.read(1, window=window) * 0.0036\n",
    "        # TODO: compute external radiation\n",
    "        #external_radiations = np.full(temperatures.shape, 14)\n",
    "        # TODO: compute global radiation\n",
    "        # global_radiations = np.full(temperatures.shape, 10)\n",
    "        # TODO: compute KCs\n",
    "        KCs = np.full(temperatures.shape, 1)\n",
    "        etc = compute_crop_evapotranspiration(\n",
    "                temperatures,\n",
    "                humidities,\n",
    "                wind_speeds,\n",
    "                external_radiations,\n",
    "                global_radiations,\n",
    "                KCs\n",
    "        )\n",
    "        dst.write(np.where(temperatures == tem.nodata, dst.nodata, etc), 1, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:58:01.128416Z",
     "start_time": "2021-04-13T16:58:01.101842Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_calculations(tile, storage):\n",
    "    \n",
    "    from functools import partial\n",
    "      \n",
    "    # Download shapefile\n",
    "    shapefile = storage.get_object(bucket=BUCKET, key='shapefile.zip', stream=True)\n",
    "    with open('shape.zip', 'wb') as shapf:\n",
    "        for chunk in iter(partial(shapefile.read, 200 * 1024 * 1024), ''):\n",
    "            if not chunk:\n",
    "                break\n",
    "            shapf.write(chunk)\n",
    "    \n",
    "    temp = storage.get_object(bucket=BUCKET, key=f'tmp/temp/{tile}/{tile}_TEMP.tif', stream=True)\n",
    "    humi = storage.get_object(bucket=BUCKET, key=f'tmp/humi/{tile}/{tile}_HUMI.tif', stream=True)\n",
    "    rad = storage.get_object(bucket=BUCKET, key=f'tmp/rad/{tile}/{tile}_RAD.tif', stream=True)\n",
    "    extrad = storage.get_object(bucket=BUCKET, key=f'tmp/extrad/{tile}/{tile}_EXTRAD.tif', stream=True)\n",
    "    wind = storage.get_object(bucket=BUCKET, key=f'tmp/wind/{tile}/{tile}_WIND.tif', stream=True)\n",
    "    \n",
    "    with rasterio.open(temp) as temp_raster:\n",
    "        with rasterio.open(humi) as humi_raster:\n",
    "            with rasterio.open(rad) as rad_raster:\n",
    "                with rasterio.open(extrad) as extrad_raster:\n",
    "                    with rasterio.open(wind) as wind_raster:\n",
    "                        profile = temp_raster.profile\n",
    "                        profile.update(nodata=0)\n",
    "        \n",
    "                        with rasterio.open('output', 'w+', **profile) as dst:\n",
    "#                             compute_global_evapotranspiration(temp_raster, humi_raster, wind_raster,\n",
    "#                                                               rad_raster, extrad_raster, dst)\n",
    "                            compute_evapotranspiration_by_shape(temp_raster, humi_raster, wind_raster,\n",
    "                                                                rad_raster, extrad_raster, dst)\n",
    "    \n",
    "    out_key = f'etc/{tile}_ETC.tif'\n",
    "    with open('output', 'rb') as output_f:\n",
    "        storage.put_object(bucket=BUCKET, key=out_key, body=output_f)\n",
    "    return out_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:58:55.822484Z",
     "start_time": "2021-04-13T16:58:54.943303Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fexec.map(combine_calculations, tiles, runtime_memory=2048)\n",
    "\n",
    "res = fexec.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPIs (Potential evaporation)\n",
    "\n",
    "[Skip KPI section](#(End-of-KPI-section---Potential-evaporation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:06:46.567960Z",
     "start_time": "2021-04-13T20:06:45.870566Z"
    }
   },
   "outputs": [],
   "source": [
    "fexec.plot(dst=\"plots/potential_evaporation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:07:04.735119Z",
     "start_time": "2021-04-13T20:07:04.729026Z"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"plots/potential_evaporation_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:07:08.400698Z",
     "start_time": "2021-04-13T20:07:08.395328Z"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"plots/potential_evaporation_timeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:08:12.027411Z",
     "start_time": "2021-04-13T20:08:12.018635Z"
    }
   },
   "outputs": [],
   "source": [
    "tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:54:33.848670Z",
     "start_time": "2021-04-13T20:54:33.645465Z"
    }
   },
   "outputs": [],
   "source": [
    "data_size = 0\n",
    "\n",
    "for obj in cloud_storage.list_objects(BUCKET):\n",
    "    for tile in tiles:\n",
    "        if obj[\"Key\"] == f'tmp/temp/{tile}/{tile}_TEMP.tif' or \\\n",
    "                obj[\"Key\"] == f'tmp/humi/{tile}/{tile}_TEMP.tif' or \\\n",
    "                obj[\"Key\"] == f'tmp/rad/{tile}/{tile}_TEMP.tif' or \\\n",
    "                obj[\"Key\"] == f'tmp/extrad/{tile}/{tile}_TEMP.tif' or \\\n",
    "                obj[\"Key\"] == f'tmp/wind/{tile}/{tile}_TEMP.tif' or \\\n",
    "                obj[\"Key\"] == 'shapefile.zip':\n",
    "            data_size += obj[\"Size\"]\n",
    "\n",
    "print(f\"Data size: {data_size / 1024**2} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KPI: Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:54:45.609853Z",
     "start_time": "2021-04-13T20:54:45.592066Z"
    }
   },
   "outputs": [],
   "source": [
    "fexec.job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:07:16.935146Z",
     "start_time": "2021-04-13T20:07:16.918524Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(fexec.log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:07:26.235760Z",
     "start_time": "2021-04-13T20:07:26.226071Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_potential_evaporation = get_process_cost(fexec)\n",
    "print(f\"The experiment cost ${cost_potential_evaporation:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KPI: Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:55:04.595689Z",
     "start_time": "2021-04-13T20:55:04.581005Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tstamps = set()\n",
    "for future in fexec.futures:\n",
    "    for key in future.stats.keys():\n",
    "        if key.endswith(\"tstamp\"):\n",
    "            tstamps.add(future.stats[key])\n",
    "            \n",
    "duration = max(tstamps) - min(tstamps)\n",
    "print(\"Duration: \" + str(duration) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:55:07.194755Z",
     "start_time": "2021-04-13T20:55:07.192029Z"
    }
   },
   "outputs": [],
   "source": [
    "throughput_potential_evaporation = data_size / duration  # Bytes/second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T20:55:09.220719Z",
     "start_time": "2021-04-13T20:55:09.212358Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Throughput: {throughput_potential_evaporation / 1024**2} MiB/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KPI: Speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we compare the execution speed of a sample process performed in last section, using different amounts of parallel workers, in order to test the scalability of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T21:10:15.560833Z",
     "start_time": "2021-04-13T21:10:15.556295Z"
    }
   },
   "outputs": [],
   "source": [
    "parallel_workers = [2, 4, 8]\n",
    "experiment_duration = dict.fromkeys(parallel_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform experiment several times and save duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T21:26:47.958535Z",
     "start_time": "2021-04-13T21:10:17.409017Z"
    }
   },
   "outputs": [],
   "source": [
    "for option in parallel_workers:\n",
    "    fexec = lithops.FunctionExecutor(\n",
    "        backend=COMPUTE_BACKEND, \n",
    "        storage=STORAGE_BACKEND, \n",
    "        runtime=RUNTIME,\n",
    "        workers=option, # Tells lithops to work w/only this number of concurrent workers\n",
    "        log_level=\"NOTSET\"\n",
    "    )\n",
    "    fexec.map(combine_calculations, tiles, runtime_memory=2048)\n",
    "    fexec.get_result()\n",
    "    \n",
    "    tstamps = set()\n",
    "    for future in fexec.futures:\n",
    "        for key in future.stats.keys():\n",
    "            if key.endswith(\"tstamp\"):\n",
    "                tstamps.add(future.stats[key])\n",
    "    duration = max(tstamps) - min(tstamps)\n",
    "    experiment_duration[option] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T21:29:20.900597Z",
     "start_time": "2021-04-13T21:29:20.893752Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization of per-worker performance relative to first experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot represents two lines:\n",
    "- **Ideal speedup**: theoretical best speedup - scenario where a 2x increment in workers results in 1/2 execution time, a 4x increment in workers results in a 1/4 execution time, etc.\n",
    "- **Lithops speedup**: actual speedup that results from the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T21:29:33.018923Z",
     "start_time": "2021-04-13T21:29:32.780739Z"
    }
   },
   "outputs": [],
   "source": [
    "duration = list(experiment_duration.values())\n",
    "theoretical_best_speedup = [(1 - parallel_workers[0] / parallel_workers[i]) * 100 for i in range(0, len(parallel_workers))]\n",
    "actual_speedup = [(1 - duration[i] / duration[0]) * 100 for i in range(0, len(duration))]\n",
    "\n",
    "plt.plot(\n",
    "    parallel_workers,\n",
    "    theoretical_best_speedup\n",
    ")\n",
    "plt.plot(\n",
    "    parallel_workers,\n",
    "    actual_speedup\n",
    ")\n",
    "plt.xlabel(\"Number of workers\")\n",
    "plt.ylabel(\"% time reduced, relative to first experiment\")\n",
    "plt.legend([\"Ideal speedup\", \"Lithops speedup (this experiment)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec.futures = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (End of KPI section - Potential evaporation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T21:30:27.539704Z",
     "start_time": "2021-04-13T21:30:26.276005Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "tile = random.choice(tiles)\n",
    "obj = io.BytesIO(cloud_storage.get_object(bucket=BUCKET, key=f'etc/{tile}_ETC.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T21:32:01.429761Z",
     "start_time": "2021-04-13T21:32:00.245568Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "with rasterio.open(obj) as src:\n",
    "    arr = src.read(1, out_shape=(src.height, src.width))\n",
    "    ax.set_title(tile)\n",
    "    img = ax.imshow(arr, cmap='Greens')\n",
    "    fig.colorbar(img, shrink=0.5)\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "obj.seek(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove intermediate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T10:06:07.571233Z",
     "start_time": "2021-03-29T10:05:14.526Z"
    }
   },
   "outputs": [],
   "source": [
    "# keys = cloud_storage.list_keys(bucket=BUCKET, prefix='')\n",
    "# keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T10:06:07.574068Z",
     "start_time": "2021-03-29T10:05:14.528Z"
    }
   },
   "outputs": [],
   "source": [
    "# for key in keys:\n",
    "#     cloud_storage.delete_object(bucket=BUCKET, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
